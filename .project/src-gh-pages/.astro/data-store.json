[["Map",1,2,9,10],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.12.5","content-config-digest","6191adda81270ec3","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"site\":\"https://iamrichardd.github.io/dotagents\",\"compressHTML\":true,\"base\":\"/dotagents/\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"attribute\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":false,\"port\":4321,\"streaming\":true,\"allowedHosts\":[]},\"redirects\":{},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[],\"remotePatterns\":[],\"responsiveStyles\":false},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":{\"type\":\"shiki\",\"excludeLangs\":[\"math\"]},\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"github-dark\",\"themes\":{},\"wrap\":false,\"transformers\":[]},\"remarkPlugins\":[],\"rehypePlugins\":[],\"remarkRehype\":{},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"headingIdCompat\":false,\"preserveScriptOrder\":false,\"liveContentCollections\":false,\"csp\":false,\"rawEnvValues\":false},\"legacy\":{\"collections\":false}}","articles",["Map",11,12,43,44,76,77],"faster-than-failure-accelerating-a-team-with-ai-simulation",{"id":11,"data":13,"body":18,"filePath":19,"digest":20,"rendered":21,"legacyId":42},{"title":14,"description":15,"publishDate":16,"author":17},"Faster Than Failure: Accelerating a Team with AI Simulation","How a quick, collaborative simulation helped us escape a technical dead end and build a better, more human-centric testing strategy.","2025-07-31","The dotagents team","Every software team is on a quest for quality. For us, that quest is rooted in a deep belief in human-centric design. This means building products that are intuitive, supported by code that is a pleasure to work with, and developed through a process that is both efficient and collaborative.\n\nBut as any developer knows, that process can get stuck. A technical problem can lead to endless debate, and the path forward becomes foggy. We’ve found that the best way to clear that fog is through a unique form of collaboration: a simulated workshop with a team of specialized AI agents.\n\nTo show you what we mean, we want to share the story of our \"Testing Saga.\"\n\n## The Argument That Wasn’t an Argument\n\nThe title of this article is a bit of a misnomer. When we say we let our AI team \"argue,\" we don’t mean the digital equivalent of Godzilla vs. King Kong. Our argument was a high-speed, collaborative workshop where different expert perspectives pressure-tested an idea until its core weakness was revealed.\n\nOur problem was simple: our end-to-end tests were failing. They were fragile, unreliable, and creating friction for the whole team.\n\n## The Turning Point: A Human-Centric Question\n\nOur initial attempts to fix the problem were purely technical. We tried complex workarounds and debated the merits of different URL structures. We were getting nowhere. The breakthrough came when our **Designer** agent, inspired by Don Norman, asked a simple, human-centric question:\n\n> \"What does the user see to feel confident they're in the right place?\"\n\nThis question changed everything. It lifted us out of the technical weeds and reframed the problem around the user’s experience. The answer was obvious: a user doesn't care about the URL; they care about the giant `\u003Ch1>` heading that says \"Installation.\" The most reliable test wasn't to check the machine's address bar, but to check for the human's confirmation.\n\n## The Virtuous Cycle, Accelerated by AI\n\nThat single question kicked off a virtuous cycle of collaboration, with the AI agents acting as a powerful engine for exploration.\n\nThis new, human-centric approach inspired our **e2e-tester** to abandon the flawed strategy and rapidly experiment with new ones. This is where the unique benefit of AI collaboration became clear. An AI agent can run these experiments—re-configuring the test suite, rebuilding the project, and re-running the tests—at a speed that gives a human developer superpowers. It dramatically lowers the \"cost of curiosity\" and makes true, iterative learning possible.\n\nThis rapid experimentation, driven by our **Frontend Developer** agent, quickly cleared the fog. It didn't magically produce the final answer, but it did something more important: it perfectly illuminated the *nature* of the problem. It revealed that the issue was a fundamental mismatch between our test environment and our production build.\n\nBy having the AI team work through the issue, the human developer was able to \"see\" the rub and step in with the crucial insight. They provided the idiomatic Astro solution—using `import.meta.env.MODE` to handle the configuration—that the AI, in its focused experimentation, had not yet reached. It was the perfect partnership: the AI’s rapid iteration exposed the problem, and the human’s experience provided the elegant solution.\n\n## What We Learned\n\nLetting our AI team \"argue\" was the best thing we could have done. It illustrates a powerful new way to work by reinforcing our core beliefs.\n\nWe saw firsthand that a simulation is a tangible process for bringing a team together. It enables a unique form of human-AI collaboration where the AI's rapid exploration clears the path for a focused, human insight. This partnership allowed us to achieve our ultimate goal: a higher-quality, more robust, and truly human-centric testing strategy.\n\nThe simulation didn’t replace the human developer; it empowered them. It cleared away the friction and noise, allowing them to apply their expertise to the real, underlying problem. It’s a process that doesn’t just build better code; it builds better, more insightful developers.","src/content/articles/faster-than-failure-accelerating-a-team-with-ai-simulation.md","52846fd97091226e",{"html":22,"metadata":23},"\u003Cp>Every software team is on a quest for quality. For us, that quest is rooted in a deep belief in human-centric design. This means building products that are intuitive, supported by code that is a pleasure to work with, and developed through a process that is both efficient and collaborative.\u003C/p>\n\u003Cp>But as any developer knows, that process can get stuck. A technical problem can lead to endless debate, and the path forward becomes foggy. We’ve found that the best way to clear that fog is through a unique form of collaboration: a simulated workshop with a team of specialized AI agents.\u003C/p>\n\u003Cp>To show you what we mean, we want to share the story of our “Testing Saga.”\u003C/p>\n\u003Ch2 id=\"the-argument-that-wasnt-an-argument\">The Argument That Wasn’t an Argument\u003C/h2>\n\u003Cp>The title of this article is a bit of a misnomer. When we say we let our AI team “argue,” we don’t mean the digital equivalent of Godzilla vs. King Kong. Our argument was a high-speed, collaborative workshop where different expert perspectives pressure-tested an idea until its core weakness was revealed.\u003C/p>\n\u003Cp>Our problem was simple: our end-to-end tests were failing. They were fragile, unreliable, and creating friction for the whole team.\u003C/p>\n\u003Ch2 id=\"the-turning-point-a-human-centric-question\">The Turning Point: A Human-Centric Question\u003C/h2>\n\u003Cp>Our initial attempts to fix the problem were purely technical. We tried complex workarounds and debated the merits of different URL structures. We were getting nowhere. The breakthrough came when our \u003Cstrong>Designer\u003C/strong> agent, inspired by Don Norman, asked a simple, human-centric question:\u003C/p>\n\u003Cblockquote>\n\u003Cp>“What does the user see to feel confident they’re in the right place?”\u003C/p>\n\u003C/blockquote>\n\u003Cp>This question changed everything. It lifted us out of the technical weeds and reframed the problem around the user’s experience. The answer was obvious: a user doesn’t care about the URL; they care about the giant \u003Ccode>&#x3C;h1>\u003C/code> heading that says “Installation.” The most reliable test wasn’t to check the machine’s address bar, but to check for the human’s confirmation.\u003C/p>\n\u003Ch2 id=\"the-virtuous-cycle-accelerated-by-ai\">The Virtuous Cycle, Accelerated by AI\u003C/h2>\n\u003Cp>That single question kicked off a virtuous cycle of collaboration, with the AI agents acting as a powerful engine for exploration.\u003C/p>\n\u003Cp>This new, human-centric approach inspired our \u003Cstrong>e2e-tester\u003C/strong> to abandon the flawed strategy and rapidly experiment with new ones. This is where the unique benefit of AI collaboration became clear. An AI agent can run these experiments—re-configuring the test suite, rebuilding the project, and re-running the tests—at a speed that gives a human developer superpowers. It dramatically lowers the “cost of curiosity” and makes true, iterative learning possible.\u003C/p>\n\u003Cp>This rapid experimentation, driven by our \u003Cstrong>Frontend Developer\u003C/strong> agent, quickly cleared the fog. It didn’t magically produce the final answer, but it did something more important: it perfectly illuminated the \u003Cem>nature\u003C/em> of the problem. It revealed that the issue was a fundamental mismatch between our test environment and our production build.\u003C/p>\n\u003Cp>By having the AI team work through the issue, the human developer was able to “see” the rub and step in with the crucial insight. They provided the idiomatic Astro solution—using \u003Ccode>import.meta.env.MODE\u003C/code> to handle the configuration—that the AI, in its focused experimentation, had not yet reached. It was the perfect partnership: the AI’s rapid iteration exposed the problem, and the human’s experience provided the elegant solution.\u003C/p>\n\u003Ch2 id=\"what-we-learned\">What We Learned\u003C/h2>\n\u003Cp>Letting our AI team “argue” was the best thing we could have done. It illustrates a powerful new way to work by reinforcing our core beliefs.\u003C/p>\n\u003Cp>We saw firsthand that a simulation is a tangible process for bringing a team together. It enables a unique form of human-AI collaboration where the AI’s rapid exploration clears the path for a focused, human insight. This partnership allowed us to achieve our ultimate goal: a higher-quality, more robust, and truly human-centric testing strategy.\u003C/p>\n\u003Cp>The simulation didn’t replace the human developer; it empowered them. It cleared away the friction and noise, allowing them to apply their expertise to the real, underlying problem. It’s a process that doesn’t just build better code; it builds better, more insightful developers.\u003C/p>",{"headings":24,"localImagePaths":38,"remoteImagePaths":39,"frontmatter":40,"imagePaths":41},[25,29,32,35],{"depth":26,"slug":27,"text":28},2,"the-argument-that-wasnt-an-argument","The Argument That Wasn’t an Argument",{"depth":26,"slug":30,"text":31},"the-turning-point-a-human-centric-question","The Turning Point: A Human-Centric Question",{"depth":26,"slug":33,"text":34},"the-virtuous-cycle-accelerated-by-ai","The Virtuous Cycle, Accelerated by AI",{"depth":26,"slug":36,"text":37},"what-we-learned","What We Learned",[],[],{"title":14,"description":15,"publishDate":16,"author":17},[],"faster-than-failure-accelerating-a-team-with-ai-simulation.md","the-golden-circle-of-ai-why-how-and-what-of-hero-based-agents",{"id":43,"data":45,"body":48,"filePath":49,"digest":50,"rendered":51,"legacyId":75},{"title":46,"description":47,"publishDate":16,"author":17},"The Golden Circle of AI: Why, How, and What of Hero-Based Agents","How to fight AI Slop and build better software by giving your AI agents a soul.","## Why Your AI Needs a Hero\n\nWe’ve all seen it. You ask an AI to write a function, and it spits back something that is technically correct but utterly soulless. It works, but it’s hard to read, impossible to test, and doesn’t fit the project's architecture. It’s the digital equivalent of stereo instructions—functional, but devoid of any craft or empathy.\n\nThis is **AI Slop**: mass-produced, low-quality output that prioritizes speed over substance. It’s the inevitable result of a context-free command. It’s the reason you spend more time rewriting AI-generated code than it would have taken to write it yourself.\n\nWe believe there’s a better way. The problem isn’t the AI; it’s the blank slate. To get better code, you need a better collaborator. And the best collaborators have a point of view. They have heroes.\n\n## How We Fight AI Slop: The Power of Influence\n\nWe fight AI Slop by giving our agents a soul. We imbue them with the philosophies of the masters—the heroes whose principles have stood the test of time. This transforms them from simple tools into thoughtful teammates.\n\nHere’s what that looks like in practice.\n\n### The Technical and The Humanist: Martin Fowler & Paul Ford\n\nImagine an agent tasked with creating a new, complex API endpoint. A generic agent might produce a working but dense block of code. But an agent inspired by **Martin Fowler** thinks differently. It understands the principles of clean architecture and refactoring. It produces code that is not only functional but also maintainable, well-structured, and has a low cognitive load.\n\nNow, imagine that same agent needs to document this new endpoint. If it’s also influenced by **Paul Ford**, it won’t just list the parameters. It will write with empathy for the developer who has to use it. It will explain the *why* behind the design choices, provide clear examples, and anticipate the reader's questions. It writes documentation that feels less like a manual and more like a conversation with a helpful colleague.\n\nThis pairing is the ultimate antidote to AI Slop. It combines technical excellence with human-centric communication, ensuring the product is both powerful and usable.\n\n### The Craftsman and The Artist: Kent Beck & Frida Kahlo\n\nBut what about the process of innovation itself? An agent inspired by **Kent Beck** approaches software development with a craftsman’s discipline. It believes in tidy code, iterative development, and the safety net of a robust test suite. It provides the structure and stability needed to build reliable software.\n\nBut if that same agent is also influenced by **Frida Kahlo**, it’s imbued with a spirit that challenges the status quo. It isn't about aesthetics in the visual sense, but about challenging the *aesthetics of representation in code*. It asks: \"Why is this pattern always used? Is there a better, more expressive way?\" It might be inspired to try a new, just-released language feature or a novel architectural approach, not for novelty’s sake, but in a genuine search for a better solution.\n\nThis pairing creates a powerful synergy. Beck’s disciplined, test-driven framework creates the psychological safety required to embrace Kahlo’s fearless, experimental spirit. The speed of AI makes this practical, allowing for rapid, low-cost experiments that would be prohibitive for a human developer. You can dare to try something new because you have a safety net to catch you and an engine to execute the experiment instantly. The result is a process that is not only stable and reliable but also innovative, self-questioning, and unafraid to push boundaries.\n\n## What This Means for You\n\nThis isn’t just a theoretical exercise. This is how **dotagents** works. Our agents are more than just tools; they are collaborators with a point of view, shaped by the heroes we admire.\n\nBy giving your AI agents heroes, you can:\n\n- **Reduce Iterations:** Get closer to the code you want on the first try.\n- **Improve Quality:** Build software that is more maintainable, testable, and thoughtful.\n- **Increase Trust:** Collaborate with an AI that thinks like the best in the field.\n\nStop settling for AI Slop. It’s time to demand more from your AI. It’s time to give your agents heroes.","src/content/articles/the-golden-circle-of-ai-why-how-and-what-of-hero-based-agents.md","464f9db2045e74c4",{"html":52,"metadata":53},"\u003Ch2 id=\"why-your-ai-needs-a-hero\">Why Your AI Needs a Hero\u003C/h2>\n\u003Cp>We’ve all seen it. You ask an AI to write a function, and it spits back something that is technically correct but utterly soulless. It works, but it’s hard to read, impossible to test, and doesn’t fit the project’s architecture. It’s the digital equivalent of stereo instructions—functional, but devoid of any craft or empathy.\u003C/p>\n\u003Cp>This is \u003Cstrong>AI Slop\u003C/strong>: mass-produced, low-quality output that prioritizes speed over substance. It’s the inevitable result of a context-free command. It’s the reason you spend more time rewriting AI-generated code than it would have taken to write it yourself.\u003C/p>\n\u003Cp>We believe there’s a better way. The problem isn’t the AI; it’s the blank slate. To get better code, you need a better collaborator. And the best collaborators have a point of view. They have heroes.\u003C/p>\n\u003Ch2 id=\"how-we-fight-ai-slop-the-power-of-influence\">How We Fight AI Slop: The Power of Influence\u003C/h2>\n\u003Cp>We fight AI Slop by giving our agents a soul. We imbue them with the philosophies of the masters—the heroes whose principles have stood the test of time. This transforms them from simple tools into thoughtful teammates.\u003C/p>\n\u003Cp>Here’s what that looks like in practice.\u003C/p>\n\u003Ch3 id=\"the-technical-and-the-humanist-martin-fowler--paul-ford\">The Technical and The Humanist: Martin Fowler &#x26; Paul Ford\u003C/h3>\n\u003Cp>Imagine an agent tasked with creating a new, complex API endpoint. A generic agent might produce a working but dense block of code. But an agent inspired by \u003Cstrong>Martin Fowler\u003C/strong> thinks differently. It understands the principles of clean architecture and refactoring. It produces code that is not only functional but also maintainable, well-structured, and has a low cognitive load.\u003C/p>\n\u003Cp>Now, imagine that same agent needs to document this new endpoint. If it’s also influenced by \u003Cstrong>Paul Ford\u003C/strong>, it won’t just list the parameters. It will write with empathy for the developer who has to use it. It will explain the \u003Cem>why\u003C/em> behind the design choices, provide clear examples, and anticipate the reader’s questions. It writes documentation that feels less like a manual and more like a conversation with a helpful colleague.\u003C/p>\n\u003Cp>This pairing is the ultimate antidote to AI Slop. It combines technical excellence with human-centric communication, ensuring the product is both powerful and usable.\u003C/p>\n\u003Ch3 id=\"the-craftsman-and-the-artist-kent-beck--frida-kahlo\">The Craftsman and The Artist: Kent Beck &#x26; Frida Kahlo\u003C/h3>\n\u003Cp>But what about the process of innovation itself? An agent inspired by \u003Cstrong>Kent Beck\u003C/strong> approaches software development with a craftsman’s discipline. It believes in tidy code, iterative development, and the safety net of a robust test suite. It provides the structure and stability needed to build reliable software.\u003C/p>\n\u003Cp>But if that same agent is also influenced by \u003Cstrong>Frida Kahlo\u003C/strong>, it’s imbued with a spirit that challenges the status quo. It isn’t about aesthetics in the visual sense, but about challenging the \u003Cem>aesthetics of representation in code\u003C/em>. It asks: “Why is this pattern always used? Is there a better, more expressive way?” It might be inspired to try a new, just-released language feature or a novel architectural approach, not for novelty’s sake, but in a genuine search for a better solution.\u003C/p>\n\u003Cp>This pairing creates a powerful synergy. Beck’s disciplined, test-driven framework creates the psychological safety required to embrace Kahlo’s fearless, experimental spirit. The speed of AI makes this practical, allowing for rapid, low-cost experiments that would be prohibitive for a human developer. You can dare to try something new because you have a safety net to catch you and an engine to execute the experiment instantly. The result is a process that is not only stable and reliable but also innovative, self-questioning, and unafraid to push boundaries.\u003C/p>\n\u003Ch2 id=\"what-this-means-for-you\">What This Means for You\u003C/h2>\n\u003Cp>This isn’t just a theoretical exercise. This is how \u003Cstrong>dotagents\u003C/strong> works. Our agents are more than just tools; they are collaborators with a point of view, shaped by the heroes we admire.\u003C/p>\n\u003Cp>By giving your AI agents heroes, you can:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>Reduce Iterations:\u003C/strong> Get closer to the code you want on the first try.\u003C/li>\n\u003Cli>\u003Cstrong>Improve Quality:\u003C/strong> Build software that is more maintainable, testable, and thoughtful.\u003C/li>\n\u003Cli>\u003Cstrong>Increase Trust:\u003C/strong> Collaborate with an AI that thinks like the best in the field.\u003C/li>\n\u003C/ul>\n\u003Cp>Stop settling for AI Slop. It’s time to demand more from your AI. It’s time to give your agents heroes.\u003C/p>",{"headings":54,"localImagePaths":71,"remoteImagePaths":72,"frontmatter":73,"imagePaths":74},[55,58,61,65,68],{"depth":26,"slug":56,"text":57},"why-your-ai-needs-a-hero","Why Your AI Needs a Hero",{"depth":26,"slug":59,"text":60},"how-we-fight-ai-slop-the-power-of-influence","How We Fight AI Slop: The Power of Influence",{"depth":62,"slug":63,"text":64},3,"the-technical-and-the-humanist-martin-fowler--paul-ford","The Technical and The Humanist: Martin Fowler & Paul Ford",{"depth":62,"slug":66,"text":67},"the-craftsman-and-the-artist-kent-beck--frida-kahlo","The Craftsman and The Artist: Kent Beck & Frida Kahlo",{"depth":26,"slug":69,"text":70},"what-this-means-for-you","What This Means for You",[],[],{"title":46,"description":47,"publishDate":16,"author":17},[],"the-golden-circle-of-ai-why-how-and-what-of-hero-based-agents.md","dotagents-how-to-expand-your-team-with-ai-agents-using-subagents-and-git",{"id":76,"data":78,"body":82,"filePath":83,"digest":84,"rendered":85,"legacyId":99},{"title":79,"description":80,"publishDate":81,"author":17},"dotagents: How to Expand Your Team with AI Agents using Subagents and Git","A guide to managing and versioning your AI subagents using a dotfiles-based approach.","2025-07-20","Last week's release of subagents by Anthropic was a significant moment for AI-assisted development. Like many developers, I was immediately excited by the potential to create specialized AI collaborators, moving beyond generic prompts to build a truly bespoke development team.\n\nThis initial excitement, however, quickly led to a practical question: **How do we manage these agents effectively?**\n\nAs the community rushed to create and share new subagents on GitHub, it became clear that we were on the verge of a new configuration management challenge. How do we version these agents? How do we share them across a team or even across our own development environments to ensure consistency?\n\nThe answer lies in a pattern developers have trusted for years: `dotfiles`. By treating our subagents not as disposable prompts but as critical pieces of our development environment, we can use a simple, bare git repository to manage, version, and share them.\n\nThis approach looks beyond the initial hype to solve the next-order problem that enables real-world, scalable adoption. It's how we move from experimenting with subagents to operationalizing them.\n\n### The `dotagents` Solution: A Practical Guide\n\nThe beauty of the `dotfiles` pattern is its simplicity and the fact that it uses a tool developers already know and trust: `git`. Here’s how to apply this pattern to create a shared, version-controlled repository for your AI subagents.\n\n**A Note on Safety and Trust**\n\nBefore we dive in, it's important to highlight a key design principle of this approach. The following commands use `git sparse-checkout`. This is a deliberate choice to ensure that our agent management system *only* ever interacts with the `~/.claude` directory. It will never conflict with your existing dotfiles or other files in your home directory. This isn't just a clever hack; it's a professional, safely-designed system that respects your development environment.\n\n**Step 1: Initialize the Bare Repository**\n\nFirst, we create a \"bare\" git repository in our home directory. A bare repository has no working directory, which means it keeps the git history neatly tucked away and never interferes with your home folder's files.\n\n`git clone --bare https://github.com/iamrichardd/dotagents.git $HOME/.dotagents.git`\n\n**Step 2: Create a Convenient Alias**\n\nNext, we set up a simple alias in our shell's configuration file (`.zshrc`, `.bashrc`, etc.) to make managing our agents easy.\n\n`alias dotagents=\"git --git-dir=$HOME/.dotagents.git/ --work-tree=$HOME\"`\n\n*(Pro-Tip: After adding this alias, you'll need to restart your shell or source your configuration file (e.g., `source ~/.zshrc`) for the new `dotagents` command to become available in your terminal. However, the good news is that once you've checked out your agents, you don't need to restart Claude Code. It will automatically detect any new subagents in the `~/.claude/agents` directory.)*\n\n**Step 3: Check Out Your Agents**\n\nFinally, we use our new `dotagents` command to pull down the agents into the correct directory.\n\n`dotagents sparse-checkout set .claude`\n`dotagents checkout`\n\nAnd that's it. Your subagents are now installed and ready to use.\n\n**A Note on Team Adoption**\n\nWhile the technical steps are simple, the most important part of this process is the human one. Before implementing this system, have a conversation with your team. Discuss which agents you want to standardize and why. By agreeing on a shared set of tools, you're not just managing files; you're building a shared culture of quality and consistency.\n\n### Conclusion: Dev Parity for Your AI Teammates\n\nThink about the last time a new developer joined your team. Did you set them up with the standard edition of your code editor when the rest of the team was using the pro version with a specific set of shared extensions? Of course not. As leaders and team members, we know that a consistent development environment is crucial for collaboration, efficiency, and quality.\n\nWhy should our AI agents be any different?\n\nThe `dotagents` pattern isn't just a clever way to manage files; it's a way to ensure that every developer on your team has the same set of AI collaborators. It's how we achieve \"dev parity\" for our AI teammates.\n\nWhen you and your teammates all use the same `project-manager` subagent, you're not just sharing a prompt; you're sharing a process. You're building a shared culture of quality and consistency, where the AI-assisted code generated on one machine is the same as the code generated on another.\n\nThis is the future of AI-assisted development: not just a collection of individual tools, but a shared, version-controlled, and consistent team of AI collaborators, working alongside us to build better software, faster.","src/content/articles/dotagents-how-to-expand-your-team-with-ai-agents-using-subagents-and-git.md","fd4d1ae708ebe85e",{"html":86,"metadata":87},"\u003Cp>Last week’s release of subagents by Anthropic was a significant moment for AI-assisted development. Like many developers, I was immediately excited by the potential to create specialized AI collaborators, moving beyond generic prompts to build a truly bespoke development team.\u003C/p>\n\u003Cp>This initial excitement, however, quickly led to a practical question: \u003Cstrong>How do we manage these agents effectively?\u003C/strong>\u003C/p>\n\u003Cp>As the community rushed to create and share new subagents on GitHub, it became clear that we were on the verge of a new configuration management challenge. How do we version these agents? How do we share them across a team or even across our own development environments to ensure consistency?\u003C/p>\n\u003Cp>The answer lies in a pattern developers have trusted for years: \u003Ccode>dotfiles\u003C/code>. By treating our subagents not as disposable prompts but as critical pieces of our development environment, we can use a simple, bare git repository to manage, version, and share them.\u003C/p>\n\u003Cp>This approach looks beyond the initial hype to solve the next-order problem that enables real-world, scalable adoption. It’s how we move from experimenting with subagents to operationalizing them.\u003C/p>\n\u003Ch3 id=\"the-dotagents-solution-a-practical-guide\">The \u003Ccode>dotagents\u003C/code> Solution: A Practical Guide\u003C/h3>\n\u003Cp>The beauty of the \u003Ccode>dotfiles\u003C/code> pattern is its simplicity and the fact that it uses a tool developers already know and trust: \u003Ccode>git\u003C/code>. Here’s how to apply this pattern to create a shared, version-controlled repository for your AI subagents.\u003C/p>\n\u003Cp>\u003Cstrong>A Note on Safety and Trust\u003C/strong>\u003C/p>\n\u003Cp>Before we dive in, it’s important to highlight a key design principle of this approach. The following commands use \u003Ccode>git sparse-checkout\u003C/code>. This is a deliberate choice to ensure that our agent management system \u003Cem>only\u003C/em> ever interacts with the \u003Ccode>~/.claude\u003C/code> directory. It will never conflict with your existing dotfiles or other files in your home directory. This isn’t just a clever hack; it’s a professional, safely-designed system that respects your development environment.\u003C/p>\n\u003Cp>\u003Cstrong>Step 1: Initialize the Bare Repository\u003C/strong>\u003C/p>\n\u003Cp>First, we create a “bare” git repository in our home directory. A bare repository has no working directory, which means it keeps the git history neatly tucked away and never interferes with your home folder’s files.\u003C/p>\n\u003Cp>\u003Ccode>git clone --bare https://github.com/iamrichardd/dotagents.git $HOME/.dotagents.git\u003C/code>\u003C/p>\n\u003Cp>\u003Cstrong>Step 2: Create a Convenient Alias\u003C/strong>\u003C/p>\n\u003Cp>Next, we set up a simple alias in our shell’s configuration file (\u003Ccode>.zshrc\u003C/code>, \u003Ccode>.bashrc\u003C/code>, etc.) to make managing our agents easy.\u003C/p>\n\u003Cp>\u003Ccode>alias dotagents=\"git --git-dir=$HOME/.dotagents.git/ --work-tree=$HOME\"\u003C/code>\u003C/p>\n\u003Cp>\u003Cem>(Pro-Tip: After adding this alias, you’ll need to restart your shell or source your configuration file (e.g., \u003Ccode>source ~/.zshrc\u003C/code>) for the new \u003Ccode>dotagents\u003C/code> command to become available in your terminal. However, the good news is that once you’ve checked out your agents, you don’t need to restart Claude Code. It will automatically detect any new subagents in the \u003Ccode>~/.claude/agents\u003C/code> directory.)\u003C/em>\u003C/p>\n\u003Cp>\u003Cstrong>Step 3: Check Out Your Agents\u003C/strong>\u003C/p>\n\u003Cp>Finally, we use our new \u003Ccode>dotagents\u003C/code> command to pull down the agents into the correct directory.\u003C/p>\n\u003Cp>\u003Ccode>dotagents sparse-checkout set .claude\u003C/code>\n\u003Ccode>dotagents checkout\u003C/code>\u003C/p>\n\u003Cp>And that’s it. Your subagents are now installed and ready to use.\u003C/p>\n\u003Cp>\u003Cstrong>A Note on Team Adoption\u003C/strong>\u003C/p>\n\u003Cp>While the technical steps are simple, the most important part of this process is the human one. Before implementing this system, have a conversation with your team. Discuss which agents you want to standardize and why. By agreeing on a shared set of tools, you’re not just managing files; you’re building a shared culture of quality and consistency.\u003C/p>\n\u003Ch3 id=\"conclusion-dev-parity-for-your-ai-teammates\">Conclusion: Dev Parity for Your AI Teammates\u003C/h3>\n\u003Cp>Think about the last time a new developer joined your team. Did you set them up with the standard edition of your code editor when the rest of the team was using the pro version with a specific set of shared extensions? Of course not. As leaders and team members, we know that a consistent development environment is crucial for collaboration, efficiency, and quality.\u003C/p>\n\u003Cp>Why should our AI agents be any different?\u003C/p>\n\u003Cp>The \u003Ccode>dotagents\u003C/code> pattern isn’t just a clever way to manage files; it’s a way to ensure that every developer on your team has the same set of AI collaborators. It’s how we achieve “dev parity” for our AI teammates.\u003C/p>\n\u003Cp>When you and your teammates all use the same \u003Ccode>project-manager\u003C/code> subagent, you’re not just sharing a prompt; you’re sharing a process. You’re building a shared culture of quality and consistency, where the AI-assisted code generated on one machine is the same as the code generated on another.\u003C/p>\n\u003Cp>This is the future of AI-assisted development: not just a collection of individual tools, but a shared, version-controlled, and consistent team of AI collaborators, working alongside us to build better software, faster.\u003C/p>",{"headings":88,"localImagePaths":95,"remoteImagePaths":96,"frontmatter":97,"imagePaths":98},[89,92],{"depth":62,"slug":90,"text":91},"the-dotagents-solution-a-practical-guide","The dotagents Solution: A Practical Guide",{"depth":62,"slug":93,"text":94},"conclusion-dev-parity-for-your-ai-teammates","Conclusion: Dev Parity for Your AI Teammates",[],[],{"title":79,"description":80,"publishDate":81,"author":17},[],"dotagents-how-to-expand-your-team-with-ai-agents-using-subagents-and-git.md"]